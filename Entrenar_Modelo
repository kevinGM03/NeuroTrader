import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Input, Dropout
from keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight

# Cargar el dataset
input_file_train = r'/content/drive/My Drive/PROYECTO/DATASET_PREPARADO/train.csv'
input_file_val = r'/content/drive/My Drive/PROYECTO/DATASET_PREPARADO/val.csv'

# Leer datos
train_data = pd.read_csv(input_file_train)
val_data = pd.read_csv(input_file_val)

# Seleccionar características y etiquetas
X_train = train_data.iloc[:, [1, 2, 3, 4, 5, 12, 13, 14, 15, 16]].values
y_train = train_data.iloc[:, 17].values

X_val = val_data.iloc[:, [1, 2, 3, 4, 5, 12, 13, 14, 15, 16]].values
y_val = val_data.iloc[:, 17].values

# Reasignar etiquetas para que sean positivas (0, 1, 2)
y_train = np.where(y_train == -1, 2, y_train)
y_val = np.where(y_val == -1, 2, y_val)

# Normalizar las características
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)

# Calcular pesos de clase para lidiar con el desbalance
class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}
print(f"Pesos de clase calculados: {class_weights_dict}")

# Crear el modelo
model = Sequential([
    Input(shape=(10,)),  # 10 características
    Dense(128, activation="relu"),
    Dropout(0.3),  # Regularización para evitar sobreajuste
    Dense(64, activation="relu"),
    Dropout(0.2),
    Dense(32, activation="relu"),
    Dense(3, activation="softmax")  # 3 salidas para las clases [0, 1, 2]
])

# Compilar el modelo
model.compile(
    optimizer=Adam(learning_rate=0.0001),  # Tasa de aprendizaje ajustada
    loss="sparse_categorical_crossentropy",  # Pérdida para clasificación multiclase
    metrics=["accuracy"]
)

# Entrenar el modelo
history = model.fit(
    X_train,
    y_train,
    validation_data=(X_val, y_val),  # Validación durante el entrenamiento
    batch_size=32,
    epochs=20,  # Aumentar las épocas para mejorar el aprendizaje
    verbose=1,
    class_weight=class_weights_dict  # Incorporar los pesos de clase
)

# Evaluar en el conjunto de validación
loss, accuracy = model.evaluate(X_val, y_val)
print(f"Pérdida en validación: {loss:.4f}")
print(f"Precisión en validación: {accuracy:.4f}")

# Guardar el modelo
model.save('/content/drive/My Drive/PROYECTO/mi_modelo.h5')

# Graficar las pérdidas y precisión durante el entrenamiento
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Pérdida (entrenamiento)')
plt.plot(history.history['val_loss'], label='Pérdida (validación)')
plt.xlabel("Épocas")
plt.ylabel("Pérdida")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Precisión (entrenamiento)')
plt.plot(history.history['val_accuracy'], label='Precisión (validación)')
plt.xlabel("Épocas")
plt.ylabel("Precisión")
plt.legend()

plt.show()

